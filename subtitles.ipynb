{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNC94vFBciRrTVh7a8BPWRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgnoob/subtitles/blob/main/subtitles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use\n",
        "* https://github.com/sgnoob/subtitles?tab=readme-ov-file#how-to-use-the-colab-file\n"
      ],
      "metadata": {
        "id": "oADWIoi9200s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ],
      "metadata": {
        "id": "5N1ZRLugK75D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQM2A9NJ1rc9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown # Input\n",
        "INPUT_SOURCE = \"yt-dlp\" # @param [\"yt-dlp\", \"GoogleDrive\"]\n",
        "\n",
        "# @markdown ### YouTube Only\n",
        "VIDEO_URL ='https://www.youtube.com/watch?v=ERIxQaoEbXs' #@param {type:\"string\"}\n",
        "COPY_VIDEO_TO_DRIVE = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### Google Drive Only\n",
        "# @markdown Please don't use names with special characters such as space.\n",
        "INPUT_FILE = \"input/test.mp4\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown # Output\n",
        "OUTPUT_DIR = 'output' #@param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown # Mel-Band-Roformer Settings\n",
        "MEL_SEGMENT_TIME = 3600 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown # Whisper Settings\n",
        "MODEL = 'large-v2' #@param {type:\"string\"}\n",
        "VAD_METHOD = 'pyannote_v3' #@param [\"silero_v4_fw\", \"silero_v5_fw\", \"silero_v3\", \"silero_v4\", \"silero_v5\", \"pyannote_v3\", \"pyannote_onnx_v3\", \"auditok\", \"webrtc\"]\n",
        "VAD_THRESHOLD = 0.1 #@param {type:\"number\"}\n",
        "# VAD_THRESHOLD default is 0.45\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown # Gemini Keys\n",
        "GEMINI_API_KEY_1 = 'NONE' #@param {type:\"string\"}\n",
        "GEMINI_API_KEY_2 = 'NONE' #@param {type:\"string\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "try:\n",
        "  GEMINI_API_KEY_1 = userdata.get('GEMINI_API_KEY_1')\n",
        "  print(\"Obtained GEMINI_API_KEY_1 from Colab Secrets.\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  GEMINI_API_KEY_2 = userdata.get('GEMINI_API_KEY_2')\n",
        "  print(\"Obtained GEMINI_API_KEY_2 from Colab Secrets.\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "GEMINI_API_KEY_1= GEMINI_API_KEY_1.strip()\n",
        "GEMINI_API_KEY_2= GEMINI_API_KEY_2.strip()\n",
        "\n",
        "if len(GEMINI_API_KEY_1) == 0 or GEMINI_API_KEY_1.lower() == \"none\":\n",
        "  GEMINI_API_KEY_1 = None\n",
        "if len(GEMINI_API_KEY_2) == 0 or GEMINI_API_KEY_2.lower() == \"none\":\n",
        "  GEMINI_API_KEY_2 = None\n",
        "\n",
        "if GEMINI_API_KEY_1 is None:\n",
        "  print(\"ERROR. GEMINI_API_KEY_1 is empty. How are we going to translate?\")\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown # Others\n",
        "DELETE_INTERMEDIATE_FILES = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Internal Use only\n",
        "MOUNT_DIR = '/content/drive'\n",
        "INPUT_FILE = f\"{MOUNT_DIR}/MyDrive/{INPUT_FILE}\"\n",
        "OUTPUT_DIR = f\"{MOUNT_DIR}/MyDrive/{OUTPUT_DIR}\"\n",
        "\n",
        "EXEC_DIR = '/content/exec'\n",
        "TMP_DIR = '/content/tmp'\n",
        "! mkdir -p {EXEC_DIR}\n",
        "if DELETE_INTERMEDIATE_FILES:\n",
        "  ! rm -rf {TMP_DIR}\n",
        "! mkdir -p {TMP_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "JpIhh9hzA_QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(MOUNT_DIR)\n",
        "\n",
        "! mkdir -p {OUTPUT_DIR}"
      ],
      "metadata": {
        "id": "SSwLGFJh5RbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ],
      "metadata": {
        "id": "JLbQwx5n6WgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "\n",
        "os.environ['MPLBACKEND'] = 'Agg' # Copied from https://github.com/Purfview/whisper-standalone-win/discussions/385\n",
        "\n",
        "! apt-get install -y aria2\n",
        "! apt-get install -y ffmpeg\n",
        "! pip3 install -U gemini-srt-translator pysubs2 yt-dlp\n",
        "\n",
        "# Download Faster-Whisper-XXL\n",
        "# I find the latest 7zip to be slightly faster in decompressing compared to apt-get\n",
        "if not os.path.exists(f'{EXEC_DIR}/Faster-Whisper-XXL/faster-whisper-xxl'):\n",
        "  ! cd {EXEC_DIR}; wget -N https://www.7-zip.org/a/7z2409-linux-x64.tar.xz\n",
        "  ! cd {EXEC_DIR}; tar -xvf 7z2409-linux-x64.tar.xz 7zz\n",
        "  ! cd {EXEC_DIR}; aria2c -x4 -s4 https://github.com/Purfview/whisper-standalone-win/releases/download/Faster-Whisper-XXL/Faster-Whisper-XXL_r245.4_linux.7z -o whisper.7z\n",
        "  ! cd {EXEC_DIR}; ./7zz x whisper.7z -aoa\n",
        "  ! chmod +x {EXEC_DIR}/Faster-Whisper-XXL/faster-whisper-xxl\n",
        "else:\n",
        "  print('Faster-Whisper-XXL/faster-whisper-xxl is already extracted, not extracting again.')\n",
        "\n",
        "# Setup Music-Source-Separation-Training (to extract vocals)\n",
        "! cd {EXEC_DIR}; git clone https://github.com/sgnoob/Mel-Band-Roformer-Vocal-Model.git\n",
        "! cd {EXEC_DIR}; pip3 install -r Mel-Band-Roformer-Vocal-Model/requirements.txt\n",
        "if not os.path.exists(f'{EXEC_DIR}/MelBandRoformer.ckpt'):\n",
        "  ! cd {EXEC_DIR}; aria2c -x4 -s4 https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt -o MelBandRoformer.ckpt"
      ],
      "metadata": {
        "id": "r5CfXW9b6ZVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download video using yt-dlp if needed"
      ],
      "metadata": {
        "id": "ksT1ZWx4MS_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if INPUT_SOURCE == \"yt-dlp\":\n",
        "  ! yt-dlp --list-formats --extractor-arg \"youtube:player_client=default,android_vr\" \"{VIDEO_URL}\"\n",
        "  RAW = ! yt-dlp --extractor-arg \"youtube:player_client=default,android_vr\" -f \"bv+ba/b\" -o \"%(id)s.%(ext)s\" \"{VIDEO_URL}\" --print filename --skip-download\n",
        "  YTDLP_FILENAME = RAW[0]\n",
        "  ! cd {TMP_DIR}; yt-dlp --extractor-arg \"youtube:player_client=default,android_vr\" -f \"bv+ba/b\" -o \"%(id)s.%(ext)s\" \"{VIDEO_URL}\"\n",
        "  INPUT_FILE = f\"{TMP_DIR}/{YTDLP_FILENAME}\"\n",
        "  ! ls -lRt {TMP_DIR}\n",
        "\n",
        "  if COPY_VIDEO_TO_DRIVE:\n",
        "    ! cp \"{INPUT_FILE}\" \"{OUTPUT_DIR}/.\"\n",
        "else:\n",
        "  print(f\"No need to download using yt-dlp. INPUT_SOURCE: {INPUT_SOURCE}\")"
      ],
      "metadata": {
        "id": "obbFz2Y-MkwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract vocals from input for better transcription\n",
        "\n",
        "Using Mel-Band-Roformer for this.\n",
        "* https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model\n"
      ],
      "metadata": {
        "id": "fpQmvVjH_PhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "p = Path(INPUT_FILE)\n",
        "FILENAME_STEM = f\"{p.stem}\"\n",
        "\n",
        "print(f\"FILENAME_STEM: {FILENAME_STEM}\")\n",
        "print(f\"TMP_DIR: {TMP_DIR}\")\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "\n",
        "if os.path.exists(f\"{OUTPUT_DIR}/{FILENAME_STEM}.jp.srt\"):\n",
        "  print(f\"{FILENAME_STEM}.jp.srt already exists, not re-running Mel-Band-Roformer.\")\n",
        "  print(f\"Delete {FILENAME_STEM}.jp.srt from your google drive if you want to re-run.\")\n",
        "elif os.path.exists(f\"{TMP_DIR}/vocals.flac\"):\n",
        "  print(f\"{TMP_DIR}/vocals.flac already exists, not re-running Mel-Band-Roformer\")\n",
        "else:\n",
        "  # We need to split the input audio into chunks to prevent Out of Memory.\n",
        "  # System RAM is the limiting factor on colab.\n",
        "  # TODO: Find some better method of splitting the input audio.\n",
        "  # We could be splitting the audio right in the middle of a word.\n",
        "  # Shouldn't be too bad since we are only splitting once every hour.\n",
        "  # For MEL_SEGMENT_TIME=3600, peak system is roughly RAM: 8.1 GiB, GPU RAM: 7.0 GiB\n",
        "  print(f'Using ffmpeg to split audio into {MEL_SEGMENT_TIME} seconds chunks')\n",
        "  command = f\"cd {TMP_DIR}; ffmpeg\"\n",
        "  command += f\" -n -i '{INPUT_FILE}'\"\n",
        "  command += f\" -vn -af 'aresample=44100' -acodec pcm_s16le -ac 2\"\n",
        "  command += f\" -f segment -segment_time {MEL_SEGMENT_TIME} -reset_timestamps 1\"\n",
        "  command += f\" part%03d.wav\"\n",
        "  print(f\"Command: {command}\")\n",
        "  ! {command}\n",
        "\n",
        "  # Run Mel-Band-Roformer to extract vocals\n",
        "  print('Running Mel-Band-Roformer to extract vocals')\n",
        "  command = f\"cd {EXEC_DIR}/Mel-Band-Roformer-Vocal-Model; python inference.py\"\n",
        "  command += f\" --model_type mel_band_roformer\"\n",
        "  command += f\" --config_path configs/config_vocals_mel_band_roformer.yaml\"\n",
        "  command += f\" --model_path {EXEC_DIR}/MelBandRoformer.ckpt\"\n",
        "  command += f\" --input_folder {TMP_DIR}\"\n",
        "  command += f\" --store_dir {TMP_DIR}\"\n",
        "  print(f\"Command: {command}\")\n",
        "  ! {command}\n",
        "\n",
        "  print(f'Using ffmpeg to recombine vocal chunks')\n",
        "  ! cd {TMP_DIR}; printf \"file '%s'\\n\" part*_vocals.wav | sort -V > mylist.txt\n",
        "  command = f\"cd {TMP_DIR}; ffmpeg\"\n",
        "  command += f\" -n -f concat -safe 0 -i mylist.txt -acodec flac -compression_level 0 vocals.flac\"\n",
        "  print(f\"Command: {command}\")\n",
        "  ! {command}\n",
        "  ! ls -lRt {TMP_DIR}"
      ],
      "metadata": {
        "id": "_7zH2c4U_bgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Transcription\n",
        "* Using https://github.com/Purfview/whisper-standalone-win"
      ],
      "metadata": {
        "id": "2CHPcBOwOPmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(f\"{OUTPUT_DIR}/{FILENAME_STEM}.jp.srt\"):\n",
        "  print(f\"{FILENAME_STEM}.jp.srt already exists, not re-running whisper transcription.\")\n",
        "  print(f\"Delete {FILENAME_STEM}.jp.srt from your google drive if you want to re-run.\")\n",
        "else:\n",
        "  print('Preparing whisper command')\n",
        "  command = f\"{EXEC_DIR}/Faster-Whisper-XXL/faster-whisper-xxl\"\n",
        "  command += f\" --model {MODEL}\"\n",
        "  command += f\" --language ja\"\n",
        "  command += f\" --vad_method {VAD_METHOD}\"\n",
        "  command += f\" --vad_threshold {VAD_THRESHOLD}\"\n",
        "  command += f\" --task transcribe\"\n",
        "  command += f\" --output_format srt\"\n",
        "  command += f\" --output_dir \\\"{TMP_DIR}\\\"\"\n",
        "  command += f\" -- \\\"{TMP_DIR}/vocals.flac\\\"\"\n",
        "  print(f\"Command: {command}\")\n",
        "\n",
        "  ! {command}\n",
        "  ! cp {TMP_DIR}/vocals.srt {OUTPUT_DIR}/{FILENAME_STEM}.jp.srt"
      ],
      "metadata": {
        "id": "RIOF0qu4ONn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate to English\n",
        "* Using https://github.com/MaKTaiL/gemini-srt-translator"
      ],
      "metadata": {
        "id": "6-0_hMZMONV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filenames\n",
        "OUT_EN_FILE = f\"{OUTPUT_DIR}/{FILENAME_STEM}.en.srt\"\n",
        "OUT_JP_FILE = f\"{OUTPUT_DIR}/{FILENAME_STEM}.jp.srt\"\n",
        "TMP_EN_FILE = f\"{TMP_DIR}/{FILENAME_STEM}.en.srt\"\n",
        "TMP_JP_FILE = f\"{TMP_DIR}/{FILENAME_STEM}.jp.srt\"\n",
        "OUT_EN_JP_FILE = f\"{OUTPUT_DIR}/{FILENAME_STEM}.en_jp.ass\"\n",
        "\n",
        "if os.path.exists(OUT_EN_FILE):\n",
        "  print(f\"{OUT_EN_FILE} already exists, not re-running gemini-srt-translator.\")\n",
        "  print(f\"Delete {OUT_EN_FILE} from your google drive if you want to re-run.\")\n",
        "else:\n",
        "  import gemini_srt_translator as gst\n",
        "  gst.gemini_api_key = GEMINI_API_KEY_1\n",
        "  gst.gemini_api_key2 = GEMINI_API_KEY_2\n",
        "  gst.target_language = \"English\"\n",
        "  gst.input_file = OUT_JP_FILE\n",
        "  gst.output_file = OUT_EN_FILE\n",
        "  gst.translate()\n",
        "\n",
        "# Combine the EN and JP subtitles into an EN_JP ASS file.\n",
        "# JP subtitles on top, EN subtitles below.\n",
        "if os.path.exists(OUT_JP_FILE) and os.path.exists(OUT_EN_FILE):\n",
        "  ! cp \"{TMP_JP_FILE}\" \"{TMP_JP_FILE}\"\n",
        "  ! cp \"{OUT_EN_FILE}\" \"{TMP_EN_FILE}\"\n",
        "  import pysubs2\n",
        "  subs_jp = pysubs2.load(TMP_JP_FILE)\n",
        "  subs_en = pysubs2.load(TMP_EN_FILE)\n",
        "  subs_en_jp = pysubs2.SSAFile()\n",
        "  subs_en_jp.styles = {\n",
        "    \"b\": pysubs2.SSAStyle(alignment=pysubs2.Alignment.BOTTOM_CENTER),\n",
        "    \"t\": pysubs2.SSAStyle(alignment=pysubs2.Alignment.TOP_CENTER),\n",
        "  }\n",
        "  for e in subs_en:\n",
        "      e.style = \"b\"\n",
        "      subs_en_jp.append(e)\n",
        "  for e in subs_jp:\n",
        "      e.style = \"t\"\n",
        "      subs_en_jp.append(e)\n",
        "\n",
        "  subs_en_jp.save(OUT_EN_JP_FILE)\n",
        "\n",
        "print(\"DONE!!!\")"
      ],
      "metadata": {
        "id": "sfNCSqOCzlXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}